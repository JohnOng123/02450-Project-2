{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02450 Project 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary goal of Project 2 is to apply supervised learning techniques (regression and classification) to predict properties or classifications of wood based on the cleaned and scaled dataset from Project 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import PIL.Image as Image\n",
    "from tqdm.notebook import tqdm\n",
    "import xlrd\n",
    "import scipy\n",
    "from scipy.linalg import svd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaned and Scaled Data from Project 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 common_species_name\n",
      "1 genus\n",
      "2 species\n",
      "3 scientific_name\n",
      "4 classification\n",
      "5 moisture_content\n",
      "6 specific_gravity\n",
      "7 modulus_of_rupture\n",
      "8 modulus_of_elasticity\n",
      "9 work_to_maximum_load\n",
      "10 compression_parallel_to_grain\n",
      "11 compression_perpendicular_to_grain\n",
      "12 shear_parallel_to_grain\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/ongji/OneDrive/Documents/DTU/02450 Introduction to Machine Learning and Data Mining/02450-Project-1/usa_wood_data_formatted.csv')\n",
    "# print(data.head())  \n",
    "\n",
    "# Clean data by removing columns with a significant amount of missing values\n",
    "removed_columns = ['side_hardness','tension_perpendicular_to_grain','impact_bending']\n",
    "data_cleaned = data.drop(columns=removed_columns)\n",
    "data_cleaned = data_cleaned.dropna()\n",
    "# print(data_cleaned.isnull().sum()) # 0 means data is clean\n",
    "\n",
    "\n",
    "# Extract attribute names (1st row, column 0 to 13)\n",
    "attributeNames = data_cleaned.columns[:13]\n",
    "for i in range(len(attributeNames)):\n",
    "    print(i, attributeNames[i])\n",
    "\n",
    "# Extract class names to python list, then encode with integers (dict)\n",
    "classLabels = data_cleaned['classification'].values\n",
    "classNames = sorted(set(classLabels))\n",
    "classDict = {className: index for index, className in enumerate(classNames)}\n",
    "y = np.array([classDict[label] for label in classLabels])\n",
    "\n",
    "\n",
    "# Preallocate memory, then extract excel data to matrix X\n",
    "X = data_cleaned.iloc[:,0:13].values\n",
    "\n",
    "# Compute values of N, M and C.\n",
    "N = len(y   )\n",
    "M = len(attributeNames)\n",
    "C = len(classNames)\n",
    "\n",
    "\n",
    "# Filter out numerical values\n",
    "X_num = data_cleaned.iloc[:,6:].values\n",
    "\n",
    "\n",
    "\n",
    "# Scale and substract mean from data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_num)\n",
    "Y = X_scaled - np.ones((N, 1)) * X_scaled.mean(axis=0)\n",
    "\n",
    "# PCA by computing SVD of Y\n",
    "U, S, Vh = svd(Y, full_matrices=False)\n",
    "\n",
    "# Compute variance explained by principal components\n",
    "rho = (S * S) / (S * S).sum()\n",
    "\n",
    "# print(\"Singular values:\", S)\n",
    "# print(\"Variance explained:\", rho)\n",
    "# print(\"Cumulative variance explained:\", np.cumsum(rho))\n",
    "\n",
    "# Convert arrays to PyTorch tensors\n",
    "X_tensor = torch.FloatTensor(X_scaled)\n",
    "y_tensor = torch.FloatTensor(y).unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   specific_gravity  modulus_of_elasticity  work_to_maximum_load  \\\n",
      "0              0.37                   1.17                   8.0   \n",
      "1              0.41                   1.38                   8.4   \n",
      "2              0.45                   1.04                  12.1   \n",
      "3              0.49                   1.60                  14.9   \n",
      "4              0.53                   1.24                  14.7   \n",
      "\n",
      "   compression_parallel_to_grain  compression_perpendicular_to_grain  \\\n",
      "0                         2960.0                               250.0   \n",
      "1                         5820.0                               440.0   \n",
      "2                         2300.0                               350.0   \n",
      "3                         5970.0                               760.0   \n",
      "4                         4180.0                               810.0   \n",
      "\n",
      "   shear_parallel_to_grain  \n",
      "0                    770.0  \n",
      "1                   1080.0  \n",
      "2                    860.0  \n",
      "3                   1570.0  \n",
      "4                   1540.0  \n",
      "X_tensor: torch.Size([214, 6])\n",
      "y_tensor: torch.Size([214, 1])\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/ongji/OneDrive/Documents/DTU/02450 Introduction to Machine Learning and Data Mining/02450-Project-1/usa_wood_data_formatted.csv')\n",
    "# print(data.head())  \n",
    "\n",
    "# Select the target variable\n",
    "target_variable = 'modulus_of_rupture'\n",
    "y_target = data_cleaned[target_variable].values\n",
    "\n",
    "selected_features = [\n",
    "    'shear_parallel_to_grain', \n",
    "    'compression_perpendicular_to_grain', \n",
    "    'specific_gravity', \n",
    "    'compression_parallel_to_grain', \n",
    "    #'modulus_of_elasticity', \n",
    "    #'work_to_maximum_load'\n",
    "]\n",
    "\n",
    "# Clean data by removing columns with a significant amount of missing values\n",
    "# removed_columns = ['side_hardness','tension_perpendicular_to_grain','impact_bending']\n",
    "# data_cleaned = data.drop(columns=removed_columns)\n",
    "# data_cleaned = data_cleaned.dropna()\n",
    "data_cleaned = data[selected_features + [target_variable]].dropna()\n",
    "\n",
    "# drop target from dataset\n",
    "X = data_cleaned.drop(columns=[target_variable]) \n",
    "\n",
    "# Keep Numerical Columns only\n",
    "X_num = X.iloc[:, 6:]  \n",
    "print(X_num.head())\n",
    "\n",
    "\n",
    "# Scale and substract mean from data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_num)\n",
    "#Y = X_scaled - np.ones((N, 1)) * X_scaled.mean(axis=0)\n",
    "\n",
    "# Update N after cleaning and target selection\n",
    "N = X_scaled.shape[0]\n",
    "\n",
    "# Convert arrays to PyTorch tensors\n",
    "X_tensor = torch.FloatTensor(X_scaled)\n",
    "y_tensor = torch.FloatTensor(y_target).unsqueeze(1)\n",
    "print(\"X_tensor:\", X_tensor.shape)\n",
    "print(\"y_tensor:\", y_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Two-Level Cross-Validation Model\n",
    "\n",
    "K1 = outer loop\n",
    "\n",
    "K2 = inner loop\n",
    "\n",
    "h = no. of hidden neurons\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ANN Model\n",
    "\n",
    "# # Define variables\n",
    "# K1 = 10\n",
    "# K2 = 10\n",
    "\n",
    "# class ANN(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super(ANN, self).__init__()\n",
    "#         self.layer1 = nn.Linear(input_dim, 128)\n",
    "#         self.layer2 = nn.Linear(128, 256)\n",
    "#         self.dropout = nn.Dropout(0.3)\n",
    "#         self.layer3 = nn.Linear(256, 128)\n",
    "#         self.layer4 = nn.Linear(128, 64)\n",
    "#         self.output_layer = nn.Linear(64, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.layer1(x))\n",
    "#         x = F.relu(self.layer2(x))\n",
    "#         x = self.dropout(x)\n",
    "#         x = F.relu(self.layer3(x))\n",
    "#         x = F.relu(self.layer4(x))\n",
    "#         x = self.output_layer(x)\n",
    "#         return x\n",
    "    \n",
    "\n",
    "# # Cross-validation\n",
    "# outer_cv = KFold(n_splits=K1, shuffle=True, random_state=42)\n",
    "# inner_cv = KFold(n_splits=K2, shuffle=True, random_state=42)\n",
    "\n",
    "# test_results =[]\n",
    "\n",
    "# # Outer Loop\n",
    "# for train_idx, test_idx in outer_cv.split(X_tensor):\n",
    "#     X_train, X_test = X_tensor[train_idx], X_tensor[test_idx]\n",
    "#     y_train, y_test = y_tensor[train_idx], y_tensor[test_idx]\n",
    "\n",
    "#     best_model = None\n",
    "#     lowest_loss = float('inf')\n",
    "\n",
    "#     # Inner Loop\n",
    "#     for train_idx_in, val_idx in inner_cv.split(X_train):\n",
    "#         X_train_inner, X_val = X_train[train_idx_in], X_train[val_idx]\n",
    "#         y_train_inner, y_val = y_train[train_idx_in], y_train[val_idx]\n",
    "\n",
    "#         # Define the model and optimizer\n",
    "#         model = ANN(X_train_inner.shape[1])\n",
    "#         optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)  # L2 regularization\n",
    "#         criterion = nn.MSELoss()\n",
    "#         #scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "#         scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=10)\n",
    "\n",
    "\n",
    "#         # Training phase\n",
    "#         for epoch in range(100):\n",
    "#             model.train()\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(X_train_inner)\n",
    "#             loss = criterion(outputs, y_train_inner)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             scheduler.step(val_loss)\n",
    "\n",
    "#             # Validation\n",
    "#             model.eval()\n",
    "#             with torch.no_grad():\n",
    "#                 val_outputs = model(X_val)\n",
    "#                 val_loss = criterion(val_outputs, y_val)\n",
    "\n",
    "#             if val_loss < lowest_loss:\n",
    "#                 best_model = model\n",
    "#                 lowest_loss = val_loss\n",
    "\n",
    "#     # Evaluation phase\n",
    "#     best_model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         test_outputs = best_model(X_test)\n",
    "#         test_loss = criterion(test_outputs, y_test)\n",
    "#         test_results.append(test_loss.item())\n",
    "\n",
    "   \n",
    "# for idx, error, in enumerate(test_results):\n",
    "#     print(f\"Fold {idx+1} MSE: {error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN Model\n",
    "\n",
    "# Define variables\n",
    "K1 = 10\n",
    "K2 = 10\n",
    "\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_dim, h):\n",
    "        super(ANN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, h)\n",
    "        self.layer2 = nn.Linear(h,h)\n",
    "        self.output_layer = nn.Linear(h, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "    \n",
    "def cross_validation(X_tensor, y_tensor, K1=10, K2=10, h_range=15):\n",
    "\n",
    "    outer_cv = KFold(n_splits=K1, shuffle=True, random_state=42)\n",
    "    inner_cv = KFold(n_splits=K2, shuffle=True, random_state=42)\n",
    "\n",
    "    test_results =[]\n",
    "    inner_errors = []\n",
    "\n",
    "    # Outer Loop\n",
    "    for i, (train_idx, test_idx) in enumerate(outer_cv.split(X_tensor)):\n",
    "        X_train, X_test = X_tensor[train_idx], X_tensor[test_idx]\n",
    "        y_train, y_test = y_tensor[train_idx], y_tensor[test_idx]\n",
    "\n",
    "        best_h = None\n",
    "        #best_lambda = None\n",
    "        best_model = None\n",
    "        lowest_error = float('inf')\n",
    "\n",
    "        # Inner Loop\n",
    "        for h in range(1, h_range + 1): # onyl try up to 20 hidden neurons\n",
    "            inner_errors_for_fold = []\n",
    "\n",
    "            for train_idx_in, val_idx in inner_cv.split(X_train):\n",
    "                X_train_inner, X_val = X_train[train_idx_in], X_train[val_idx]\n",
    "                y_train_inner, y_val = y_train[train_idx_in], y_train[val_idx]\n",
    "\n",
    "                # Define model based on h  \n",
    "                model = ANN(X_train_inner.shape[1], h)\n",
    "                optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "                criterion = nn.MSELoss()\n",
    "\n",
    "                # Training phase\n",
    "                for epoch in range(100):\n",
    "                    model.train()\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(X_train_inner)\n",
    "                    loss = criterion(outputs, y_train_inner)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "\n",
    "                # Evaluation phase\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_outputs = model(X_val)\n",
    "                    #val_loss = criterion(val_outputs, y_val)\n",
    "                    val_error = mean_squared_error(y_val.numpy(), val_outputs.numpy())\n",
    "                    inner_errors_for_fold.append(val_error)\n",
    "                \n",
    "            \n",
    "            # Find best h for this fold\n",
    "            avg_inner_error = np.mean(inner_errors_for_fold)\n",
    "            if avg_inner_error < lowest_error: \n",
    "                lowest_error = avg_inner_error\n",
    "                best_h = h\n",
    "                \n",
    "                    \n",
    "\n",
    "        # Evaluate the best model based on best h\n",
    "        best_model = ANN(X_train.shape[1], best_h)\n",
    "        optimizer = optim.Adam(best_model.parameters(), lr=0.001)\n",
    "        criterion = nn.MSELoss()\n",
    "        for epoch in range(50):\n",
    "            best_model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = best_model(X_train)\n",
    "            loss = criterion(outputs, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        best_model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = best_model(X_test)\n",
    "            test_error = mean_squared_error(y_test.numpy(), test_outputs.numpy())\n",
    "\n",
    "        test_results.append((i+1, best_h, test_error))\n",
    "    \n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 | Best h: 14 | Test MSE: 116229632.0000\n",
      "Fold 2 | Best h: 15 | Test MSE: 124493728.0000\n",
      "Fold 3 | Best h: 15 | Test MSE: 113124992.0000\n",
      "Fold 4 | Best h: 15 | Test MSE: 82540528.0000\n",
      "Fold 5 | Best h: 15 | Test MSE: 103642512.0000\n",
      "Fold 6 | Best h: 15 | Test MSE: 65518048.0000\n",
      "Fold 7 | Best h: 15 | Test MSE: 106540224.0000\n",
      "Fold 8 | Best h: 15 | Test MSE: 97876840.0000\n",
      "Fold 9 | Best h: 15 | Test MSE: 115852264.0000\n",
      "Fold 10 | Best h: 15 | Test MSE: 118145816.0000\n"
     ]
    }
   ],
   "source": [
    "results = cross_validation(X_tensor, y_tensor)\n",
    "for result in results:\n",
    "    print(f\"Fold {result[0]} | Best h: {result[1]} | Test MSE: {result[2]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract the h values from the results\n",
    "h_values = [result[1] for result in results]\n",
    "\n",
    "# Plot the histogram for the frequency plot of h\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(h_values, bins=20, edgecolor='black', alpha=0.7)\n",
    "plt.xticks(range(int(min(h_values))-1, int(max(h_values))+2, 1))\n",
    "plt.xlabel('h')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency Plot for Number h')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "Use the features identified as significant from the PCA analysis. \n",
    "\n",
    "This includes 'modulus of rupture', 'shear parallel to grain', 'compression parallel to grain', 'modulus of elasticity', 'work to maximum load', and 'specific gravity'. \n",
    "\n",
    "These are strong candidates for your predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression \n",
    "\n",
    "To predict a continuous variable based on other variables. \n",
    "\n",
    "To predict the values/property of one feature based on other features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
