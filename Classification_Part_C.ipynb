{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02450 Project 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary goal of Project 2 is to apply supervised learning techniques (regression and classification) to predict properties or classifications of wood based on the cleaned and scaled dataset from Project 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import PIL.Image as Image\n",
    "from tqdm.notebook import tqdm\n",
    "import xlrd\n",
    "import scipy\n",
    "from scipy.linalg import svd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import (\n",
    "    figure,\n",
    "    grid,\n",
    "    legend,\n",
    "    loglog,\n",
    "    plot,\n",
    "    semilogx,\n",
    "    show,\n",
    "    subplot,\n",
    "    title,\n",
    "    xlabel,\n",
    "    ylabel,\n",
    ")\n",
    "from sklearn.naive_bayes import BernoulliNB  # Use BernoulliNB for binary classification\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn.linear_model as lm\n",
    "from matplotlib.pylab import figure, hist, plot, show, subplot, xlabel, ylabel\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from dtuimldmtools import *\n",
    "from dtuimldmtools.statistics.statistics import correlated_ttest\n",
    "from dtuimldmtools import confmatplot, rocplot\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaned and Scaled Data from Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hardwood= 1, Softwood = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common_species_name                   0\n",
      "genus                                 0\n",
      "species                               0\n",
      "scientific_name                       0\n",
      "classification                        0\n",
      "moisture_content                      0\n",
      "specific_gravity                      0\n",
      "modulus_of_rupture                    0\n",
      "modulus_of_elasticity                 0\n",
      "work_to_maximum_load                  0\n",
      "compression_parallel_to_grain         0\n",
      "compression_perpendicular_to_grain    0\n",
      "shear_parallel_to_grain               0\n",
      "dtype: int64\n",
      "['Wood Type' 'Moisture Content' 'modulus_of_rupture'\n",
      " 'modulus_of_elasticity' 'work_to_maximum_load'\n",
      " 'compression_parallel_to_grain' 'compression_perpendicular_to_grain']\n",
      "1 (214, 7)\n",
      "2 (214, 9)\n",
      "X-shape (214, 8)\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "data = pd.read_csv(cwd + '/usa_wood_data_formatted.csv')\n",
    "\n",
    "removed_columns = ['side_hardness','tension_perpendicular_to_grain','impact_bending']\n",
    "data_cleaned = data.drop(columns=removed_columns)\n",
    "data_cleaned = data_cleaned.dropna()\n",
    "print(data_cleaned.isnull().sum()) # 0 means data is clean\n",
    "\n",
    "data_arr = np.array(data_cleaned)  # Attributes are columns\n",
    "attributeNames = [name for name in data_cleaned.columns]\n",
    "attributeNames = attributeNames[7:12]\n",
    "attributeNames = np.concatenate((['Wood Type', 'Moisture Content'], attributeNames))\n",
    "print(attributeNames)\n",
    "\n",
    "for i in range(data_arr.shape[1]):\n",
    "    val, count = np.unique(data_arr[:,i], return_counts=True)\n",
    "    #print(val.shape)        # Print how many unique values of each attribute exist \n",
    "                            # Probably dont do one of k coding for first 4 attributes since they have so many unique values\n",
    "\n",
    "data_adj = data_arr[:,6:13]\n",
    "print(\"1\",data_adj.shape)\n",
    "\n",
    "for i in range(2):\n",
    "    OoK = np.zeros([data_arr.shape[0], 1])\n",
    "    val, count = np.unique(data_arr[:,5 - i], return_counts=True)\n",
    "    \n",
    "    for j in range(data_arr.shape[0]):\n",
    "        if data_arr[j,5-i] == val[0]:\n",
    "            OoK[j, 0] = 1\n",
    "    data_adj = np.concatenate((OoK, data_adj), 1)\n",
    "print(\"2\",data_adj.shape)\n",
    "\n",
    "\n",
    "#classsification\n",
    "y = data_adj[:,0]\n",
    "X = data_adj[:,1:9]\n",
    "#regression\n",
    "#y = data_adj[:,4]\n",
    "# = np.concatenate((data_adj[:,0:3], data_adj[:,5:]), 1)\n",
    "N, M = X.shape\n",
    "\n",
    "X = X.astype(np.float64)  # Convert to float32 (or float64 if necessary)\n",
    "y = y.astype(np.float64)  # Convert y to float32\n",
    "\n",
    "#print(y)\n",
    "print(\"X-shape\", X.shape)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)  # Features as float32\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(1)  # Target variable as float32 and reshaped to (N, 1)\n",
    "#X_tensor = torch.FloatTensor(X)\n",
    "#y_tensor = torch.FloatTensor(X_scaled[:,6])\n",
    "#y_tensor = torch.FloatTensor(y).unsqueeze(1)\n",
    "#numpy.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K = 10\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.80, stratify=y)\n",
    "def logistic_regression(X_train, y_train, X_test, y_test, l):\n",
    "    \n",
    "    # Standardize the training and test set based on training set mean and std\n",
    "    mu = np.mean(X_train, axis=0)\n",
    "    sigma = np.std(X_train, axis=0)\n",
    "    X_train = (X_train - mu) / sigma\n",
    "    X_test = (X_test - mu) / sigma\n",
    "\n",
    "    # Set regularization strength with C (inverse of lambda)\n",
    "    mdl = LogisticRegression(penalty=\"l2\", C=1 / l, max_iter=1000)\n",
    "    mdl.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on training and test sets\n",
    "    y_train_est = mdl.predict(X_train)\n",
    "    y_test_est = mdl.predict(X_test)\n",
    "\n",
    "    # Calculate error rates\n",
    "    train_error_rate = np.mean(y_train_est != y_train)\n",
    "    test_error_rate = np.mean(y_test_est != y_test)\n",
    "\n",
    "    # Calculate coefficient norm\n",
    "    coefficient_norm = np.linalg.norm(mdl.coef_)\n",
    "\n",
    "    # Print results for this lambda\n",
    "   # print(f\"\\nLambda = {l} (C = {1 / l}):\")\n",
    "    #print(\"Train Error Rate:\", train_error_rate)\n",
    "    #print(\"Test Error Rate:\", test_error_rate)\n",
    "   # print(\"Coefficient Norm:\", coefficient_norm)\n",
    "    # Return values for further use\n",
    "    return test_error_rate #, coefficient_norm,  l, train_error_rate,\n",
    "\n",
    "#l = 0.01\n",
    "#lambda_value = 0.01  # Define a single lambda value\n",
    "#logistic_regression(X_train, y_train, X_test, y_test, lambda_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3313953488372093"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.80, stratify=y)\n",
    "def naive_classifier_binary(X_train, y_train, X_test, y_test, alpha, fit_prior=True):\n",
    "    # Standardize the training and test set based on training set mean and std\n",
    "    mu = np.mean(X_train, axis=0)\n",
    "    sigma = np.std(X_train, axis=0)\n",
    "    X_train = (X_train - mu) / sigma\n",
    "    X_test = (X_test - mu) / sigma\n",
    "    \n",
    "    # Initialize and fit BernoulliNB for binary classification with the given alpha\n",
    "    nb_classifier = BernoulliNB(alpha=alpha, fit_prior=fit_prior)\n",
    "    nb_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions for test and train sets\n",
    "    y_train_est = nb_classifier.predict(X_train)\n",
    "    y_test_est = nb_classifier.predict(X_test)\n",
    "    \n",
    "    # Calculate error rates\n",
    "    train_error = np.mean(y_train_est != y_train)\n",
    "    test_error = np.mean(y_test_est != y_test)\n",
    "    \n",
    "    #print(f\"Alpha: {alpha} | Train Error Rate: {train_error * 100:.2f}% | Test Error Rate: {test_error * 100:.2f}%\")\n",
    "    \n",
    "    return test_error #alpha, train_error,\n",
    "\n",
    "# Example usage:\n",
    "alpha = 1.0  # Set a specific alpha value\n",
    "naive_classifier_binary(X_train, y_train, X_test, y_test, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline, based on splitting data before, but doing standardization in this split\n",
    "#K = 10\n",
    "#CV = model_selection.KFold(n_splits=K, shuffle=True)\n",
    "#K = 10\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.95, stratify=y)\n",
    "def baseline_classification(y_train,y_test):  \n",
    "    error_rates = []\n",
    "   \n",
    "    # Find the most frequent class in the training labels\n",
    "    unique_classes, counts = np.unique(y_train, return_counts=True)\n",
    "    most_frequent_class = unique_classes[np.argmax(counts)]\n",
    "    #print(\"The most frequent class is:\", most_frequent_class)\n",
    "\n",
    "    #Create predictions for the test set using the most frequent class\n",
    "    y_pred_baseline = np.full(y_test.shape, most_frequent_class)  # predict the most frequent class for all\n",
    "\n",
    "    #Evaluate the baseline model\n",
    "    baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
    "    baseline_error = 1 - baseline_accuracy\n",
    "    error_rates.append(baseline_error)\n",
    "\n",
    "    # Calculate the average test error rate across all folds\n",
    "    avg_test_error_rate = np.mean(error_rates)\n",
    "    #print(f\"Average Test Error Rate: {avg_test_error_rate:.2f}\")\n",
    "    #print(f\"Baseline Accuracy: {baseline_accuracy:.2f}\")\n",
    "    return avg_test_error_rate\n",
    "#baseline_classification(y_train,y_test)\n",
    "#baseline_classification(y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix saved as 'data3.csv' in /Users/selmakuhlmann/Documents/WS 2024/MachineLearning/Python/MachLearn/Project 2/02450-Project-2\n",
      "1.0000 22.2300 0.3636 0.4715 0.0455 0.5000\n",
      "2.0000 18.4207 0.1818 0.4292 0.1818 0.4545\n",
      "3.0000 26.8270 0.1818 0.5179 0.0455 0.4545\n",
      "4.0000 7.1969 0.3182 0.2683 0.1818 0.2727\n",
      "5.0000 0.0954 0.3333 0.0309 0.2857 0.2857\n",
      "6.0000 10.4811 0.4286 0.3237 0.1905 0.4762\n",
      "7.0000 12.6486 0.0952 0.3556 0.1905 0.4286\n",
      "8.0000 0.0791 0.2857 0.0281 0.1905 0.3810\n",
      "9.0000 4.9417 0.1429 0.2223 0.0952 0.5238\n",
      "10.0000 100.0000 0.3333 1.0000 0.2381 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 22.229964825261934, 0.36363636363636365, 0.47148663634573923,\n",
       "        0.045454545454545456, 0.5],\n",
       "       [2, 18.420699693267146, 0.18181818181818182, 0.42919342601287763,\n",
       "        0.18181818181818182, 0.4545454545454546],\n",
       "       [3, 26.826957952797247, 0.18181818181818182, 0.517947467923121,\n",
       "        0.045454545454545456, 0.4545454545454546],\n",
       "       [4, 7.196856730011514, 0.3181818181818182, 0.2682695795279725,\n",
       "        0.18181818181818182, 0.2727272727272727],\n",
       "       [5, 0.09540954763499938, 0.3333333333333333, 0.030888435964774818,\n",
       "        0.2857142857142857, 0.2857142857142857],\n",
       "       [6, 10.481131341546853, 0.42857142857142855, 0.32374575428176433,\n",
       "        0.19047619047619047, 0.47619047619047616],\n",
       "       [7, 12.648552168552959, 0.09523809523809523, 0.35564803062231287,\n",
       "        0.19047619047619047, 0.4285714285714286],\n",
       "       [8, 0.07906043210907697, 0.2857142857142857, 0.028117686979742307,\n",
       "        0.19047619047619047, 0.38095238095238093],\n",
       "       [9, 4.941713361323833, 0.14285714285714285, 0.22229964825261944,\n",
       "        0.09523809523809523, 0.5238095238095238],\n",
       "       [10, 100.0, 0.3333333333333333, 1.0, 0.23809523809523808,\n",
       "        0.33333333333333337]], dtype=object)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Model parameters\n",
    "#lambdas = np.logspace(-2, 0, 50)  # From 10^-2 to 10^0 (0.01 to 1) with 50 points\n",
    "#alphas = np.logspace(-2, 0, 50)\n",
    "#alphas = [0.1, 0.5, 1.0, 2.0, 5.0]\n",
    "#number_of_logreg_models = len(lambdas)\n",
    "#number_of_alphas = len(alphas)\n",
    "\n",
    "def two_factor_cross_validation(X, y, alphas, lambdas, K1=10, K2=10):\n",
    "    # Model parameters\n",
    "    outer_cv = KFold(n_splits=K1, shuffle=True, random_state=42)\n",
    "    inner_cv = KFold(n_splits=K2, shuffle=True, random_state=42)\n",
    "    # Model parameters\n",
    "    lambdas = np.logspace(-2, 0, 50)  # From 10^-2 to 10^0 (0.01 to 1) with 50 points\n",
    "    alphas = np.logspace(-2, 2, 50)\n",
    "    #alphas = [0.1, 0.5, 1.0, 2.0, 5.0]\n",
    "    number_of_logreg_models = len(lambdas)\n",
    "    number_of_alphas = len(alphas)\n",
    "    \n",
    "    # Store results for each model\n",
    "    results_matrix = np.zeros((K1, 6), dtype=object)\n",
    "    r_results_matrix = np.zeros((K1, 6), dtype=object)\n",
    "    outer_error_array = np.zeros(K1)\n",
    "    selected_models = np.zeros(K1, dtype=int)  # To store the index of the selected model\n",
    "    selected_alphas = np.zeros(K1)  # To store selected alphas for Naive Bayes\n",
    "\n",
    "    # Set numpy print options to four decimal places\n",
    "    #np.set_printoptions(formatter={'float': '{:0.4f}'.format})\n",
    "    outer_fold = 0\n",
    "    for outer_train_index, outer_test_index in outer_cv.split(X):\n",
    "        X_train_outer, X_test_outer = X[outer_train_index], X[outer_test_index]\n",
    "        y_train_outer, y_test_outer = y[outer_train_index], y[outer_test_index]\n",
    "\n",
    "        # Inner cross-validation loop\n",
    "        inner_error_matrix = np.zeros((K2, number_of_logreg_models + number_of_alphas + 1))\n",
    "        inner_genE_array = np.zeros(number_of_logreg_models + number_of_alphas + 1)\n",
    "\n",
    "        inner_fold = 0\n",
    "        for inner_train_index, inner_val_index in inner_cv.split(X_train_outer):\n",
    "            X_train_inner, X_val_inner = X_train_outer[inner_train_index], X_train_outer[inner_val_index]\n",
    "            y_train_inner, y_val_inner = y_train_outer[inner_train_index], y_train_outer[inner_val_index]\n",
    "\n",
    "            # Logistic regression errors\n",
    "            for l in range(len(lambdas)):\n",
    "                inner_error_matrix[inner_fold, l] = logistic_regression(X_train_inner, y_train_inner, X_val_inner, y_val_inner, lambdas[l])\n",
    "                #print(\"LogReg Nr. \"+str(l)+\" error: \"+str(inner_error_matrix[inner_fold, l]))\n",
    "\n",
    "            # Naive classifier errors\n",
    "            for alph in range(len(alphas)):\n",
    "                inner_error_matrix[inner_fold, number_of_logreg_models + alph] = naive_classifier_binary(X_train_inner, y_train_inner, X_val_inner, y_val_inner, alphas[alph])\n",
    "                #print(\"Alpha Nr. \"+str(alph)+\" error: \"+str(inner_error_matrix[inner_fold + number_of_logreg_models,alph])) #+ nr_of_logreg_models or number_of_alphas?\n",
    "                #print(\"Alpha Nr. \"+str(alph)+\" error: \"+str(inner_error_matrix[inner_fold, number_of_logreg_models + alph]))\n",
    "\n",
    "            # Baseline error\n",
    "            inner_error_matrix[inner_fold, -1] = baseline_classification(y_train_outer, y_test_outer)\n",
    "            #print(\"Baseline error: \"+str(inner_error_matrix[inner_fold, -1]))\n",
    "            #print(\"Inner fold \"+str(inner_fold)+\" done\")\n",
    "            inner_fold += 1\n",
    "\n",
    "        # Select the best model based on the minimum error\n",
    "        for index in range(len(inner_genE_array)):\n",
    "            inner_genE_array[index] = inner_error_matrix.T[index].mean()\n",
    "\n",
    "        # Model selection logic: finding the best model\n",
    "        selected_model = np.argmin(inner_genE_array)\n",
    "        #print(f\"Best model for outer fold {outer_fold}: Model {selected_model} with error {inner_genE_array[selected_model]}\")\n",
    "        \n",
    "        # Store the selected model index\n",
    "        selected_models[outer_fold] = selected_model\n",
    "\n",
    "        # If Logistic Regression, store the lambda value\n",
    "        if selected_model < number_of_logreg_models:\n",
    "            selected_lambdas = lambdas[selected_model]\n",
    "            logistic_error = logistic_regression(X_train_outer, y_train_outer, X_test_outer, y_test_outer, selected_lambdas)\n",
    "            results_matrix[outer_fold, 3] = selected_lambdas  # Lambda for Logistic Regression\n",
    "            results_matrix[outer_fold, 4] = logistic_error  # Logistic Regression error\n",
    "        else:\n",
    "            logistic_error = None\n",
    "        #print(selected_model)\n",
    "        #print(number_of_logreg_models)\n",
    "        #print(number_of_logreg_models + number_of_alphas)\n",
    "        # If Naive Bayes, store the alpha value\n",
    "        if selected_model < number_of_logreg_models:\n",
    "        #if selected_model >= number_of_logreg_models and selected_model < (number_of_logreg_models + number_of_alphas):\n",
    "            selected_alpha = alphas[selected_model - number_of_logreg_models]\n",
    "            naive_error = naive_classifier_binary(X_train_outer, y_train_outer, X_test_outer, y_test_outer, selected_alpha)\n",
    "            results_matrix[outer_fold, 1] = selected_alpha  # Alpha for Naive Bayes\n",
    "            results_matrix[outer_fold, 2] = naive_error  # Naive Bayes error\n",
    "        else:\n",
    "            naive_error = None\n",
    "        #print(\"selected model\",selected_model)\n",
    "        # Evaluate the baseline classifier on the outer test set\n",
    "        baseline_error = baseline_classification(y_train_outer, y_test_outer)\n",
    "        results_matrix[outer_fold, 5] = baseline_error  # Baseline error\n",
    "\n",
    "        # Store the results for the fold\n",
    "        results_matrix[outer_fold, 0] = outer_fold + 1  # Fold number\n",
    "\n",
    "        #print(\"Outer fold \"+str(outer_fold) +\" done with errors:\")\n",
    "        #print(f\"Logistic Regression error: {logistic_error}, Naive Bayes error: {naive_error}, Baseline error: {baseline_error}\")\n",
    "        outer_fold += 1\n",
    "    #final_matrix = np.vstack(results_matrix)\n",
    "    #print(final_matrix)\n",
    "    # Print each element in the matrix with four decimal places\n",
    "    for row in results_matrix:\n",
    "        print(\" \".join(f\"{elem:.4f}\" for elem in row))\n",
    "    # Convert the matrix to a DataFrame\n",
    "    #print(\"Matrix saved as 'results_matrix.xlsx'\")\n",
    "    return results_matrix\n",
    "     \n",
    "np.savetxt(\"data3.csv\", results_matrix, delimiter = \",\")\n",
    "folder_path = \"/Users/selmakuhlmann/Documents/WS 2024/MachineLearning/Python/MachLearn/Project 2/02450-Project-2\"  # Replace with your desired folder path\n",
    "# Ensure the folder exists\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "file_path = os.path.join(folder_path, \"data3.csv\")\n",
    "np.savetxt(file_path, results_matrix, delimiter=\",\", fmt=\"%.4f\")  # '%.4f' formats to 4 decimal places\n",
    "print(f\"Matrix saved as 'data3.csv' in {folder_path}\")         \n",
    "   \n",
    "    # Display final results matrix\n",
    "    #print(\"\\nResults Matrix (10x6):\\n\", results_matrix)\n",
    " #   return results_matrix\n",
    "\n",
    "# Call the function to perform the two-factor cross-validation\n",
    "two_factor_cross_validation(X, y, alphas, lambdas, K1=10, K2=10)\n",
    "\n",
    "#np.save(\"results_matrix.npy\", results_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0.47148663634573923 0.2727272727272727 0.47148663634573923\n",
      "  0.045454545454545456 0.5]\n",
      " [2 0.42919342601287763 0.18181818181818182 0.42919342601287763\n",
      "  0.18181818181818182 0.4545454545454546]\n",
      " [3 0.517947467923121 0.13636363636363635 0.517947467923121\n",
      "  0.045454545454545456 0.4545454545454546]\n",
      " [4 0.2682695795279725 0.3181818181818182 0.2682695795279725\n",
      "  0.18181818181818182 0.2727272727272727]\n",
      " [5 0.030888435964774818 0.3333333333333333 0.030888435964774818\n",
      "  0.2857142857142857 0.2857142857142857]\n",
      " [6 0.32374575428176433 0.42857142857142855 0.32374575428176433\n",
      "  0.19047619047619047 0.47619047619047616]\n",
      " [7 0.35564803062231287 0.14285714285714285 0.35564803062231287\n",
      "  0.19047619047619047 0.4285714285714286]\n",
      " [8 0.028117686979742307 0.2857142857142857 0.028117686979742307\n",
      "  0.19047619047619047 0.38095238095238093]\n",
      " [9 0.22229964825261944 0.14285714285714285 0.22229964825261944\n",
      "  0.09523809523809523 0.5238095238095238]\n",
      " [10 1.0 0.3333333333333333 1.0 0.23809523809523808 0.33333333333333337]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "mcnemar() missing 1 required positional argument: 'yhatB'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m  \u001b[38;5;66;03m# Significance level for the test\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Perform McNemar's test for each pair of columns\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Compare column 2 (Naive Bayes) and column 4 (Logistic Regression)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m thetahat_2_4, CI_2_4, p_2_4 \u001b[38;5;241m=\u001b[39m \u001b[43mmcnemar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComparison between columns 2 and 4 (Naive Bayes vs Logistic Regression):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtheta =\u001b[39m\u001b[38;5;124m\"\u001b[39m, thetahat_2_4, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m CI:\u001b[39m\u001b[38;5;124m\"\u001b[39m, CI_2_4, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp-value:\u001b[39m\u001b[38;5;124m\"\u001b[39m, p_2_4)\n",
      "\u001b[0;31mTypeError\u001b[0m: mcnemar() missing 1 required positional argument: 'yhatB'"
     ]
    }
   ],
   "source": [
    "#cwd = os.getcwd()\n",
    "#data = pd.read_csv(cwd + '/data3.csv')\n",
    "# Load the saved results_matrix if needed\n",
    "#results_matrix = np.load(\"results_matrix.npy\")\n",
    "#results_matrix = two_factor_cross_validation(X, y, alphas, lambdas, K1=10, K2=10)\n",
    "#print(results_matrix)\n",
    "from dtuimldmtools import mcnemar\n",
    "\n",
    "alpha = 0.05  # Significance level for the test\n",
    "\n",
    "# Perform McNemar's test for each pair of columns\n",
    "# Compare column 2 (Naive Bayes) and column 4 (Logistic Regression)\n",
    "thetahat_2_4, CI_2_4, p_2_4 = mcnemar(results_matrix[:, 2], results_matrix[:, 4], alpha=alpha)\n",
    "print(\"Comparison between columns 2 and 4 (Naive Bayes vs Logistic Regression):\")\n",
    "print(\"theta =\", thetahat_2_4, \" CI:\", CI_2_4, \"p-value:\", p_2_4)\n",
    "\n",
    "# Compare column 2 (Naive Bayes) and column 5 (Baseline)\n",
    "thetahat_2_5, CI_2_5, p_2_5 = mcnemar(results_matrix[:, 2], results_matrix[:, 5], alpha=alpha)\n",
    "print(\"\\nComparison between columns 2 and 5 (Naive Bayes vs Baseline):\")\n",
    "print(\"theta =\", thetahat_2_5, \" CI:\", CI_2_5, \"p-value:\", p_2_5)\n",
    "\n",
    "# Compare column 4 (Logistic Regression) and column 5 (Baseline)\n",
    "thetahat_4_5, CI_4_5, p_4_5 = mcnemar(results_matrix[:, 4], results_matrix[:, 5], alpha=alpha)\n",
    "print(\"\\nComparison between columns 4 and 5 (Logistic Regression vs Baseline):\")\n",
    "print(\"theta =\", thetahat_4_5, \" CI:\", CI_4_5, \"p-value:\", p_4_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum [55 3.6475966659109242 2.5757575757575757 3.6475966659109242\n",
      " 1.6450216450216448 4.1103896103896105]\n",
      "Mean [5.5 0.36475966659109244 0.25757575757575757 0.36475966659109244\n",
      " 0.16450216450216448 0.41103896103896104]\n"
     ]
    }
   ],
   "source": [
    "#Optimal_lambda = result_matrix [:,4]\n",
    "print(\"Sum\",sum(results_matrix [:,:]))\n",
    "print(\"Mean\",(sum(results_matrix [:,:])/10))\n",
    "#optimal lambda: 0.36475966659109244, but probably wrong"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
